# Alok Singh

| <alokbeniwal@gmail.com> • 408-421-5658 •
  [alok.blog](https://alok.github.io/) •
  [github.com/alok](https://www.github.com/alok/)

## Education and Coursework

2013-2017

:   **BA, Mathematics**; University of California, Berkeley

    Deep Reinforcement Learning, Machine Learning, Functional Analysis,
    Real Analysis, Topology, Measure Theory, Artificial Intelligence,
    Algebraic Topology

## Publications

**Spiky Corrupt Markov Decision Processes** IJCAI 2019, AI Safety
Workshop

## Relevant Experience

**Machine Learning Scientist, Terrafuse** (2019)

Replace (slow) classical climate simulation models with faster ones
using deep generative models and super-resolution.

**Machine Learning Consultant, Papert Labs** (2018)

Consulted companies on how to use ML. Worked on time series forecasting
and automating our ML pipeline, cutting runtime by 2 hours.

**Ray, AMPLab** (2018)

Maintained PyTorch support for distributed ML computing library
[Ray](https://github.com/ray-project/ray/).

**Recurse Center** (2017)

Worked on deep reinforcement learning. Implemented DAgger, DQN, and
policy gradient methods. Also worked on metaheuristics such as genetic
algorithms and simulated annealing.

**Data Scientist Intern, Radius Intelligence** (2015)

Did EDA using Apache Spark. Integrated customer data with our own,
increasing total dataset size by 3x.

## Relevant Projects

**Network Compression**

Implemented model compression to test the conclusion of the paper
*Understanding Deep Learning Requires Rethinking Generalization*. Blog
post and code
[here](https://alok.github.io/2018/01/12/compressing-neural-networks-to-see-if-they-learn).

**Parallel PPO**

Implemented advanced policy gradient algorithm and tuned to achieve
superhuman performance on Atari.

**DAgger**

Implemented and gave a talk about DAgger at the Recurse Center.

**Deep Q-Network**

Implemented DQN with optimizations to play Atari games to superhuman
levels.

## Skills

-   Python, PyTorch, TensorFlow, Bash, UNIX, Haskell
